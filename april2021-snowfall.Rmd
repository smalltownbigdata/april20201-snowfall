---
title: "Snow Stripes: Visualizing the rhythms of winter with daily snowfall data in R"
author: "Nikki Inglis // Small Town Big Data"
date: "April 6, 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/ncinglis/Desktop/snowfall/april2021-snowfall")
```

This tutorial accompanies the Small Town Big Data blog post [Snow Stripes: Rhythms of winter snowfalls in Colorado's famed ski towns](https://www.smalltownbigdata.com/post/colorado-ski-town-snowfall-data).

The code described here culminates in the creation of the [Snow Stripes app, available here. Make your own Snow Stripes, no code required!](https://smalltownbigdata.shinyapps.io/snowstripes/)
***

### Snow.   


This tutorial offers an introduction to making Snow Stripes, a minimalist visualization inspired by the [Warming Stripes project by Ed Hawkins](https://showyourstripes.info/). The code I used here is partially inspired by a [tutorial from Dominique Roye](https://dominicroye.github.io/en/2018/how-to-create-warming-stripes-in-r/). But instead of warming global temperatures, we're using daily snowfall totals from the National Weather Service to capture the vibe of winter in a ski town. In this tutorial we'll cover:

  * Dealing with date formats
  * Plotting minimalist stripes of daily snowfall data, a.k.a. Snow Stripes
  * Using lapply() to recreate data cleaning procedures for multiple datasets
  * A cursory intro to Shiny app creation*
  

* _This was my first time making a Shiny app. I'll be sharing the code I used to make the Snow Stripes app, however, I'm far from the right person to teach you how to do it yourself. This portion will include links to the tutorials I used to create mine but a warning: if I learned one thing, it's that Shiny apps can get complicated very quickly._  
  

To start, I recommend downloading [RStudio](https://rstudio.com/products/rstudio/download/). 
Open up a new .R file and start cutting and pasting! This is a good one for beginnners as the dataset is unfrightening and I've included them all already in .tsv format. The plotting is fairly straightforward and the data cleaning tasks are good ones to learn at the beginning of your journey! 

***

**Let's check out these data.** 

National Weather Service daily snowfall data records are straightforward. It has just two columns: date and snowfall in inches. In these data, sometimes there is an "M" or a "T" thrown in there. That's when the station could not record a snowfall amount for some reason. What made me fall for this dataset is its longevity: some of the snowfall records go back to 1893. Imagine a winter in the high Rockies before cars and before....chairlifts! While we'll constrain our analysis to the most reliable years (1920 and later) just knowing how far we can peek into weather history with data is immensely satisfying. 


### Loading .tsv data and working with dreaded dates

```{r load, message=F, warning=F, fig.align='center'}
#Use this command to install the packages needed for this tutorial:
#install.packages(c("ggplot2", "lubridate", "dplyr"))
library(ggplot2)
library(lubridate)
library(dplyr)

#Read in the data and rename the columns
steamboat<-read.table(file = 'data/steamboatdaily.tsv', sep = '\t', header = TRUE)
names(steamboat)<-c("date", "snow")

#To start, the snowfall value is a string, so R isn't reading it as a numeric value. Let's make that into a number and change those letters to NAs. 
steamboat$snow<-as.numeric(steamboat$snow)

#The date column is a date. But R doesn't know it's a date yet. It's thinks it's a string - to R, it could be a list of literally anything. But we want R to know it's a date so we can manipulate the data by time period. In the lubridate library, as.Date() turns that column into an R-recognized date. The format we enter is how we're telling R to read what's written in the column. 
steamboat$date<-as.Date(steamboat$date, format ="%Y-%m-%d")

#We have a calendar problem. I don't like how Jan. 1 is the begnning of the year. Because, in a ski town, Jan 1 is the MIDDLE of the year. We all know this. So, we're going to make a new column called snow.year, which is a July to July calendar named after the year it ends in. This makes winter the middle of the year, which is akin to how it feels when winter is the centerpiece of common experience. In this line, we're just pulling the year from each XXXXXXXXXXX
steamboat$snow.year<-year(steamboat$date) + (month(steamboat$date) >= 7)

#Make a vector of each individual snow year
years<-unique(steamboat$snow.year)

#Loop through each snow year and number the days for each year, starting over at 1 each July 1. 
#for (i in 1:length(years)) {
  #steamboat[steamboat$snow.year==years[i],]$plotnumber <- seq(1:nrow(steamboat[steamboat$snow.year==years[i],]))
#}


steamboat<-steamboat %>% group_by(snow.year) %>% mutate(plotnumber = 1:n())

#While I pulled numbers back to 1900, there are too many NAs in the early data. We'll keep this analysis to the last 100 years for the most reliable data. 
snow<-steamboat[steamboat$snow.year > 1920 & steamboat$snow.year < 2021,]

#Here's what we're working with:
head(snow)

```


### Earning your Snow Stripes with `ggplot2`

```{r plot, message=F, warning=F, fig.align='center'}
#I made this color ramp using an online color ramp generator so I could play with the different values in real time. I highly recommend using online tools like  and. You can copy those hex codes into R when you find a combination you like. Or use mine: 
cols<-colorRampPalette(colors=c("#E8DED1","#7FD27F", "#5BA1FF", "#932EDF", "#FF00D0"), bias =2)

#This object is made of a lot of specific theme elements that ggplot2 needs to make this plot exactly how we want. Mostly, these commands make all the defaults disappear. We can also dial in the fonts we want. Making this a separate object makes it super easy to add to ggplot objects later on. 

theme_strip <- theme_minimal()+
  theme(axis.text.y = element_blank(),
        axis.line.y = element_blank(),
        axis.title = element_blank(),
        panel.grid.major = element_blank(),
        legend.title = element_blank(),
        axis.text.x = element_text(vjust = 3),
        panel.grid.minor = element_blank(),
        plot.title = element_text(size = 14, face = "bold"),
        legend.text = element_text(size=16, color="grey95", family="sans"),
        axis.text.x = element_text(size=10, color="grey95", family="sans" ),
        legend.title = element_text(size=16, color="grey95", family="sans"),
        rect = element_rect(fill="transparent")
  )



#Here is a Snow Stripe! I started with the first year Steamboat Resort operated: the 1963-64 season:
test<-steamboat[steamboat$snow.year==1964,]

ggplot(test, aes(x = plotnumber, y = 1, fill = snow))+
  geom_tile() +
  scale_fill_gradientn(colors=cols(300), na.value = "#E8DED1") +
  scale_x_continuous(breaks=c(1,185,365), labels=c("July", "Jan", "July")) +
  guides(fill = guide_colorbar(barwidth = 1))+ theme_strip + 
  labs(fill="snowfall (in.)")
```


## What about some other ski towns? Let's load in a few more daily snowfall histories so we can make more Snow Stripes from around Colorado.

### Lapply() to the rescue 

We want to do what we did to the Steamboat data above and repeat it for the data for each new ski town's snowfall data. We could use a nice tidy for loop to do that, like I demonstrated in XXX blog post. However, most advanced R users will tell you that for loops can be cumbersome and slow. They will eventually convince you that lapply() is the way. Here's how to appease these masters: 

```{r lapply, message=F, warning=F, fig.align='center'}
#Let's load in others
vail<-read.table(file = 'data/vaildaily.tsv', sep = '\t', header = TRUE)
breck<-read.table(file = 'data/breckdaily.tsv', sep = '\t', header = TRUE)
wp<-read.table(file = 'data/winterparkdaily.tsv', sep = '\t', header = TRUE)
cb<-read.table(file = 'data/crestedbuttedaily.tsv', sep = '\t', header = TRUE)
telluride<-read.table(file = 'data/telluridedaily.tsv', sep = '\t', header = TRUE)
silverton<-read.table(file = 'data/silvertondaily.tsv', sep = '\t', header = TRUE)


#We take each of these objects and make them into a list. The list object "combineddata" contains the data for all the towns. 
combineddata<-list(steamboat,vail,breck,wp,cb,telluride,silverton)

#You can access parts of the list by position with the [[]] brackets. For example, the Steamboat data is in the first position and can be viewed with:
head(combineddata[[1]])

#Now, we take every single step we did to clean the Steamboat data and wrap it in a function-making machine. Meaning, we're making a custom function where the argument (x) is the dataset we want to clean: 

cleaning<-function(x) {
names(x)<-c("date", "snow")
x$date<-as.Date(x$date, format ="%Y-%m-%d")
x$snow<-as.numeric(x$snow)
x$snow.year<-year(x$date) + (month(x$date) >= 7)
years<-unique(x$snow.year)
for (i in 1:length(years)) {
  x[x$snow.year==years[i],]$plotnumber <- seq(1:nrow(x[x$snow.year==years[i],]))
}
x<-x %>% group_by(snow.year) %>% mutate(plotnumber = 1:n())
snow<-x[x$snow.year > 1920 & x$snow.year < 2021,]
snow
}

# THEN, we pass that entire list of datasets to that function. The 'l' in lapply() means list. So you 'apply' the function to a 'list.' Argument one is the list, argument two is the custom function we made. 
data_list<-lapply(combineddata, FUN = cleaning)

#The data_list object is now a list of perfectly cleaned data all ready for Snow Stripe-making 
names(data_list)<-c("Steamboat", "Vail", "Breckenridge", "Winter Park", "Crested Butte", "Telluride", "Silverton")


#You can make a year of Snow Stripes from any year of any member of this list like so:

listtest<-data_list[["Crested Butte"]][data_list[["Crested Butte"]]$snow.year==2009,]

ggplot(listtest, aes(x = plotnumber, y = 1, fill = snow))+
  geom_tile() +
  scale_fill_gradientn(colors=cols(300), na.value = "#E8DED1") +
  scale_x_continuous(breaks=c(1,185,365), labels=c("July", "Jan", "July")) +
  guides(fill = guide_colorbar(barwidth = 1))+ theme_strip + 
  labs(fill="snowfall (in.)")

```


```{r shiny, eval=F}




```
[email me!](https://www.smalltownbigdata.com/contact). 

**Next post drops April 6.**
